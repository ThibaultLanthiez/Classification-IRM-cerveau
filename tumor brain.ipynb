{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "from pathlib import Path\n",
    "import keras\n",
    "import tensorflow as tf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2297 images belonging to 4 classes.\n",
      "Found 573 images belonging to 4 classes.\n",
      "Found 394 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dir = Path('brain tumor/Training/')\n",
    "test_dir = Path('brain tumor/Testing/')\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "height=224 # images ont des tailles diffÃ©rentes donc on prend 150x150 pixels\n",
    "width=224\n",
    "channel = 3\n",
    "seed=1337\n",
    "batch_size = 64\n",
    "num_classes = 4\n",
    "\n",
    "# Training generator\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255, # Multiply the data by the rescale (after applying all other transformations)\n",
    "        rotation_range=40, # Degree range for random rotations\n",
    "        width_shift_range=0.2, # Fraction of total width\n",
    "        height_shift_range=0.2, # Fraction of total height\n",
    "        shear_range=0.2, # Shear Intensity\n",
    "        zoom_range=0.2, # Range for random zoom\n",
    "        horizontal_flip=True, # Randomly flip inputs horizontally\n",
    "        fill_mode='nearest', # Points outside the boundaries of the input are filled according to 'aaaaaaaa|abcd|dddddddd'\n",
    "        validation_split=0.2) # test\n",
    "\n",
    "# train_datagen = ImageDataGenerator(preprocessing_function=keras.applications.VGG16.preprocess_input)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_dir, \n",
    "                                                    target_size=(height,width), # Size to resize images\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    seed=seed,\n",
    "                                                    shuffle=True,\n",
    "                                                    class_mode='categorical', # class_mode='sparse' --> ordinal car tl le demande                             \n",
    "                                                    subset='training')\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(train_dir, \n",
    "                                                         target_size=(height,width),\n",
    "                                                         batch_size=batch_size,\n",
    "                                                         seed=seed,\n",
    "                                                         shuffle=True,\n",
    "                                                         class_mode='categorical', # class_mode='categorical' --> one-hot  \n",
    "                                                         subset='validation')\n",
    "\n",
    "# Test generator\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_directory(test_dir, \n",
    "                                                  target_size=(height,width),                                                   \n",
    "                                                  batch_size=batch_size,\n",
    "                                                  seed=seed,\n",
    "                                                  shuffle=False,\n",
    "                                                  class_mode='categorical') # class_mode='categorical' --> one-hot  \n",
    "\n",
    "train_num = train_generator.samples\n",
    "validation_num = validation_generator.samples\n",
    "test_num = test_generator.samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "35/35 [==============================] - 35s 1s/step - loss: 1.3141 - acc: 0.3587 - val_loss: 1.5161 - val_acc: 0.3145\n",
      "Epoch 2/200\n",
      "35/35 [==============================] - 35s 1s/step - loss: 1.2275 - acc: 0.4411 - val_loss: 1.2438 - val_acc: 0.4538\n",
      "Epoch 3/200\n",
      "35/35 [==============================] - 34s 981ms/step - loss: 1.0857 - acc: 0.5207 - val_loss: 1.2185 - val_acc: 0.4637\n",
      "Epoch 4/200\n",
      "35/35 [==============================] - 34s 977ms/step - loss: 1.0227 - acc: 0.5598 - val_loss: 1.3512 - val_acc: 0.4401\n",
      "Epoch 5/200\n",
      "35/35 [==============================] - 34s 985ms/step - loss: 0.9703 - acc: 0.5880 - val_loss: 1.1322 - val_acc: 0.4971\n",
      "Epoch 6/200\n",
      "35/35 [==============================] - 34s 959ms/step - loss: 0.9508 - acc: 0.6049 - val_loss: 1.1010 - val_acc: 0.5226\n",
      "Epoch 7/200\n",
      "35/35 [==============================] - 34s 957ms/step - loss: 0.8871 - acc: 0.6244 - val_loss: 1.1999 - val_acc: 0.5422\n",
      "Epoch 8/200\n",
      "35/35 [==============================] - 33s 950ms/step - loss: 0.8174 - acc: 0.6576 - val_loss: 1.2416 - val_acc: 0.5344\n",
      "Epoch 9/200\n",
      "35/35 [==============================] - 34s 958ms/step - loss: 0.8884 - acc: 0.6235 - val_loss: 1.0630 - val_acc: 0.5108\n",
      "Epoch 10/200\n",
      "35/35 [==============================] - 33s 946ms/step - loss: 0.7968 - acc: 0.6754 - val_loss: 0.9975 - val_acc: 0.5449\n",
      "Epoch 11/200\n",
      "35/35 [==============================] - 35s 1s/step - loss: 0.7765 - acc: 0.6626 - val_loss: 1.2076 - val_acc: 0.5697\n",
      "Epoch 12/200\n",
      "35/35 [==============================] - 40s 1s/step - loss: 0.7684 - acc: 0.6696 - val_loss: 1.1011 - val_acc: 0.4912\n",
      "Epoch 13/200\n",
      "35/35 [==============================] - 48s 1s/step - loss: 0.7245 - acc: 0.6932 - val_loss: 1.1613 - val_acc: 0.4931\n",
      "Epoch 14/200\n",
      "35/35 [==============================] - 34s 971ms/step - loss: 0.7065 - acc: 0.7049 - val_loss: 0.7652 - val_acc: 0.6228\n",
      "Epoch 15/200\n",
      "35/35 [==============================] - 35s 989ms/step - loss: 0.6911 - acc: 0.7085 - val_loss: 0.9517 - val_acc: 0.5481\n",
      "Epoch 16/200\n",
      "35/35 [==============================] - 34s 968ms/step - loss: 0.6463 - acc: 0.7313 - val_loss: 0.8889 - val_acc: 0.6208\n",
      "Epoch 17/200\n",
      "35/35 [==============================] - 34s 958ms/step - loss: 0.6489 - acc: 0.7259 - val_loss: 1.0757 - val_acc: 0.5363\n",
      "Epoch 18/200\n",
      "35/35 [==============================] - 41s 1s/step - loss: 0.6483 - acc: 0.7215 - val_loss: 1.0253 - val_acc: 0.5580\n",
      "Epoch 19/200\n",
      "35/35 [==============================] - 36s 1s/step - loss: 0.6399 - acc: 0.7438 - val_loss: 0.8741 - val_acc: 0.6465\n",
      "Epoch 20/200\n",
      "35/35 [==============================] - 35s 1s/step - loss: 0.5728 - acc: 0.7696 - val_loss: 0.8257 - val_acc: 0.6228\n",
      "Epoch 21/200\n",
      "35/35 [==============================] - 35s 992ms/step - loss: 0.5502 - acc: 0.7752 - val_loss: 0.9389 - val_acc: 0.6405\n",
      "Epoch 22/200\n",
      "35/35 [==============================] - 39s 1s/step - loss: 0.5591 - acc: 0.7788 - val_loss: 1.0273 - val_acc: 0.6621\n",
      "Epoch 23/200\n",
      "35/35 [==============================] - 36s 1s/step - loss: 0.5615 - acc: 0.7725 - val_loss: 0.5701 - val_acc: 0.6424\n",
      "Epoch 24/200\n",
      "35/35 [==============================] - 36s 1s/step - loss: 0.5152 - acc: 0.7998 - val_loss: 0.9520 - val_acc: 0.6149\n",
      "Epoch 25/200\n",
      "35/35 [==============================] - 37s 1s/step - loss: 0.5068 - acc: 0.8030 - val_loss: 0.7649 - val_acc: 0.6444\n",
      "Epoch 26/200\n",
      "35/35 [==============================] - 33s 940ms/step - loss: 0.5245 - acc: 0.7850 - val_loss: 1.0238 - val_acc: 0.6346\n",
      "Epoch 27/200\n",
      "35/35 [==============================] - 33s 938ms/step - loss: 0.5134 - acc: 0.7987 - val_loss: 0.9809 - val_acc: 0.6621\n",
      "Epoch 28/200\n",
      "35/35 [==============================] - 33s 934ms/step - loss: 0.5010 - acc: 0.7985 - val_loss: 0.5197 - val_acc: 0.6895\n",
      "Epoch 29/200\n",
      "35/35 [==============================] - 35s 1s/step - loss: 0.4687 - acc: 0.8080 - val_loss: 0.9201 - val_acc: 0.6817\n",
      "Epoch 30/200\n",
      "35/35 [==============================] - 36s 1s/step - loss: 0.4612 - acc: 0.8055 - val_loss: 0.8045 - val_acc: 0.6837\n",
      "Epoch 31/200\n",
      "35/35 [==============================] - 40s 1s/step - loss: 0.4737 - acc: 0.8146 - val_loss: 1.1870 - val_acc: 0.6621\n",
      "Epoch 32/200\n",
      "35/35 [==============================] - 45s 1s/step - loss: 0.4406 - acc: 0.8196 - val_loss: 0.8808 - val_acc: 0.6621\n",
      "Epoch 33/200\n",
      "35/35 [==============================] - 47s 1s/step - loss: 0.4460 - acc: 0.8195 - val_loss: 0.8828 - val_acc: 0.6896\n",
      "Epoch 34/200\n",
      "35/35 [==============================] - 43s 1s/step - loss: 0.4207 - acc: 0.8343 - val_loss: 0.5253 - val_acc: 0.7230\n",
      "Epoch 35/200\n",
      "35/35 [==============================] - 44s 1s/step - loss: 0.3881 - acc: 0.8442 - val_loss: 0.5851 - val_acc: 0.7328\n",
      "Epoch 36/200\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.4123 - acc: 0.8303 - val_loss: 1.0219 - val_acc: 0.7151\n",
      "Epoch 37/200\n",
      "35/35 [==============================] - 34s 983ms/step - loss: 0.4524 - acc: 0.8124 - val_loss: 0.8089 - val_acc: 0.7227\n",
      "Epoch 38/200\n",
      "35/35 [==============================] - 37s 1s/step - loss: 0.3833 - acc: 0.8554 - val_loss: 0.7887 - val_acc: 0.6935\n",
      "Epoch 39/200\n",
      "35/35 [==============================] - 37s 1s/step - loss: 0.3615 - acc: 0.8482 - val_loss: 0.7635 - val_acc: 0.6798\n",
      "Epoch 40/200\n",
      "35/35 [==============================] - 36s 1s/step - loss: 0.4346 - acc: 0.8267 - val_loss: 0.5622 - val_acc: 0.7269\n",
      "Epoch 41/200\n",
      "35/35 [==============================] - 36s 1s/step - loss: 0.3741 - acc: 0.8576 - val_loss: 0.6729 - val_acc: 0.7171\n",
      "Epoch 42/200\n",
      "35/35 [==============================] - 36s 1s/step - loss: 0.3675 - acc: 0.8495 - val_loss: 0.5932 - val_acc: 0.7171\n",
      "Epoch 43/200\n",
      "35/35 [==============================] - 36s 1s/step - loss: 0.3661 - acc: 0.8576 - val_loss: 0.7044 - val_acc: 0.7544\n",
      "Epoch 44/200\n",
      "35/35 [==============================] - 35s 999ms/step - loss: 0.3543 - acc: 0.8585 - val_loss: 0.6655 - val_acc: 0.7466\n",
      "Epoch 45/200\n",
      "35/35 [==============================] - 34s 980ms/step - loss: 0.3359 - acc: 0.8720 - val_loss: 0.6494 - val_acc: 0.7210\n",
      "Epoch 46/200\n",
      "35/35 [==============================] - 35s 993ms/step - loss: 0.3080 - acc: 0.8822 - val_loss: 0.7219 - val_acc: 0.7852\n",
      "Epoch 47/200\n",
      "35/35 [==============================] - 39s 1s/step - loss: 0.3243 - acc: 0.8719 - val_loss: 0.6852 - val_acc: 0.7878\n",
      "Epoch 48/200\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.3150 - acc: 0.8755 - val_loss: 0.8871 - val_acc: 0.7151\n",
      "Epoch 49/200\n",
      "35/35 [==============================] - 39s 1s/step - loss: 0.2974 - acc: 0.8854 - val_loss: 0.8908 - val_acc: 0.7721\n",
      "Epoch 50/200\n",
      "35/35 [==============================] - 37s 1s/step - loss: 0.3084 - acc: 0.8877 - val_loss: 0.6875 - val_acc: 0.7446\n",
      "Epoch 51/200\n",
      "35/35 [==============================] - 35s 1s/step - loss: 0.2982 - acc: 0.8777 - val_loss: 0.5721 - val_acc: 0.7466\n",
      "Epoch 52/200\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.2964 - acc: 0.8800 - val_loss: 0.5276 - val_acc: 0.7800\n",
      "Epoch 53/200\n",
      "35/35 [==============================] - 36s 1s/step - loss: 0.2912 - acc: 0.8948 - val_loss: 0.6869 - val_acc: 0.7721\n",
      "Epoch 54/200\n",
      "35/35 [==============================] - 36s 1s/step - loss: 0.3078 - acc: 0.8889 - val_loss: 0.5658 - val_acc: 0.7603\n",
      "Epoch 55/200\n",
      "35/35 [==============================] - 35s 1s/step - loss: 0.2946 - acc: 0.8916 - val_loss: 0.5737 - val_acc: 0.7598\n",
      "Epoch 56/200\n",
      "35/35 [==============================] - 37s 1s/step - loss: 0.2812 - acc: 0.8926 - val_loss: 0.4205 - val_acc: 0.7917\n",
      "Epoch 57/200\n",
      "35/35 [==============================] - 37s 1s/step - loss: 0.2575 - acc: 0.9024 - val_loss: 0.7702 - val_acc: 0.7721\n",
      "Epoch 58/200\n",
      "35/35 [==============================] - 40s 1s/step - loss: 0.2732 - acc: 0.8957 - val_loss: 0.9876 - val_acc: 0.7937\n",
      "Epoch 59/200\n",
      "35/35 [==============================] - 36s 1s/step - loss: 0.2748 - acc: 0.8955 - val_loss: 0.4337 - val_acc: 0.8035\n",
      "Epoch 60/200\n",
      "35/35 [==============================] - 35s 998ms/step - loss: 0.2630 - acc: 0.9028 - val_loss: 0.7013 - val_acc: 0.7957\n",
      "Epoch 61/200\n",
      "35/35 [==============================] - 34s 961ms/step - loss: 0.2266 - acc: 0.9169 - val_loss: 0.3051 - val_acc: 0.7682\n",
      "Epoch 62/200\n",
      "35/35 [==============================] - 33s 951ms/step - loss: 0.3110 - acc: 0.8831 - val_loss: 0.5330 - val_acc: 0.7701\n",
      "Epoch 63/200\n",
      "35/35 [==============================] - 33s 943ms/step - loss: 0.2753 - acc: 0.8996 - val_loss: 0.5184 - val_acc: 0.7898\n",
      "Epoch 64/200\n",
      "35/35 [==============================] - 33s 940ms/step - loss: 0.2532 - acc: 0.9086 - val_loss: 0.5585 - val_acc: 0.7715\n",
      "Epoch 65/200\n",
      "35/35 [==============================] - 36s 1s/step - loss: 0.2328 - acc: 0.9176 - val_loss: 0.5803 - val_acc: 0.8094\n",
      "Epoch 66/200\n",
      "35/35 [==============================] - 35s 996ms/step - loss: 0.2629 - acc: 0.8979 - val_loss: 1.0807 - val_acc: 0.7525\n",
      "Epoch 67/200\n",
      "35/35 [==============================] - 34s 975ms/step - loss: 0.2684 - acc: 0.8971 - val_loss: 0.8173 - val_acc: 0.7132\n",
      "Epoch 68/200\n",
      "35/35 [==============================] - 35s 1s/step - loss: 0.2625 - acc: 0.9000 - val_loss: 0.6452 - val_acc: 0.8114\n",
      "Epoch 69/200\n",
      "35/35 [==============================] - 36s 1s/step - loss: 0.2248 - acc: 0.9230 - val_loss: 0.9409 - val_acc: 0.8369\n",
      "Epoch 70/200\n",
      "35/35 [==============================] - 35s 992ms/step - loss: 0.2306 - acc: 0.9100 - val_loss: 0.3501 - val_acc: 0.8094\n",
      "Epoch 71/200\n",
      "35/35 [==============================] - 35s 1s/step - loss: 0.2190 - acc: 0.9176 - val_loss: 0.8354 - val_acc: 0.7819\n",
      "Epoch 72/200\n",
      "35/35 [==============================] - 33s 938ms/step - loss: 0.2313 - acc: 0.9136 - val_loss: 0.4548 - val_acc: 0.7800\n",
      "Epoch 73/200\n",
      "35/35 [==============================] - 33s 948ms/step - loss: 0.2078 - acc: 0.9180 - val_loss: 0.6697 - val_acc: 0.8047\n",
      "Epoch 74/200\n",
      "35/35 [==============================] - 40s 1s/step - loss: 0.2278 - acc: 0.9086 - val_loss: 0.8149 - val_acc: 0.7662\n",
      "Epoch 75/200\n",
      "35/35 [==============================] - 35s 1s/step - loss: 0.1990 - acc: 0.9248 - val_loss: 0.8573 - val_acc: 0.8094\n",
      "Epoch 76/200\n",
      "35/35 [==============================] - 35s 988ms/step - loss: 0.2113 - acc: 0.9257 - val_loss: 0.3921 - val_acc: 0.8271\n",
      "Epoch 77/200\n",
      "35/35 [==============================] - 34s 984ms/step - loss: 0.2322 - acc: 0.9140 - val_loss: 0.5576 - val_acc: 0.8134\n",
      "Epoch 78/200\n",
      "35/35 [==============================] - 34s 962ms/step - loss: 0.2241 - acc: 0.9154 - val_loss: 0.4108 - val_acc: 0.8389\n",
      "Epoch 79/200\n",
      "35/35 [==============================] - 35s 997ms/step - loss: 0.2387 - acc: 0.9122 - val_loss: 0.5839 - val_acc: 0.7937\n",
      "Epoch 80/200\n",
      "35/35 [==============================] - 34s 982ms/step - loss: 0.2000 - acc: 0.9207 - val_loss: 0.2327 - val_acc: 0.8350\n",
      "Epoch 81/200\n",
      "35/35 [==============================] - 34s 957ms/step - loss: 0.1834 - acc: 0.9312 - val_loss: 0.5268 - val_acc: 0.8016\n",
      "Epoch 82/200\n",
      "35/35 [==============================] - 33s 940ms/step - loss: 0.1893 - acc: 0.9308 - val_loss: 0.4382 - val_acc: 0.8340\n",
      "Epoch 83/200\n",
      "35/35 [==============================] - 36s 1s/step - loss: 0.1953 - acc: 0.9270 - val_loss: 0.2985 - val_acc: 0.8369\n",
      "Epoch 84/200\n",
      "35/35 [==============================] - 35s 995ms/step - loss: 0.2029 - acc: 0.9212 - val_loss: 0.6656 - val_acc: 0.8625\n",
      "Epoch 85/200\n",
      "35/35 [==============================] - 34s 986ms/step - loss: 0.1904 - acc: 0.9275 - val_loss: 0.5912 - val_acc: 0.8468\n",
      "Epoch 86/200\n",
      "35/35 [==============================] - 34s 976ms/step - loss: 0.2061 - acc: 0.9216 - val_loss: 0.7391 - val_acc: 0.8448\n",
      "Epoch 87/200\n",
      "35/35 [==============================] - 34s 964ms/step - loss: 0.1977 - acc: 0.9261 - val_loss: 0.7298 - val_acc: 0.8546\n",
      "Epoch 88/200\n",
      "35/35 [==============================] - 33s 955ms/step - loss: 0.2083 - acc: 0.9254 - val_loss: 0.3471 - val_acc: 0.8409\n",
      "Epoch 89/200\n",
      "35/35 [==============================] - 33s 952ms/step - loss: 0.1865 - acc: 0.9310 - val_loss: 0.5979 - val_acc: 0.8114\n",
      "Epoch 90/200\n",
      "35/35 [==============================] - 33s 937ms/step - loss: 0.1842 - acc: 0.9299 - val_loss: 0.4144 - val_acc: 0.7878\n",
      "Epoch 91/200\n",
      "35/35 [==============================] - 33s 948ms/step - loss: 0.1900 - acc: 0.9344 - val_loss: 0.3109 - val_acc: 0.8262\n",
      "Epoch 92/200\n",
      "35/35 [==============================] - 36s 1s/step - loss: 0.1645 - acc: 0.9425 - val_loss: 0.7350 - val_acc: 0.8251\n",
      "Epoch 93/200\n",
      "35/35 [==============================] - 35s 1s/step - loss: 0.1885 - acc: 0.9330 - val_loss: 0.5114 - val_acc: 0.8291\n",
      "Epoch 94/200\n",
      "35/35 [==============================] - 35s 989ms/step - loss: 0.1651 - acc: 0.9385 - val_loss: 0.4817 - val_acc: 0.8625\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "                     keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(height, width, channel)),\n",
    "                     keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "                     keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "                     keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "                     keras.layers.Conv2D(64, (3, 3), activation='relu'), # add\n",
    "                     keras.layers.MaxPooling2D(pool_size=(2, 2)), # add\n",
    "    \n",
    "                     keras.layers.Conv2D(128, (3, 3), padding='same', activation='relu'), # 64\n",
    "                     keras.layers.Conv2D(128, (3, 3), activation='relu'), # 64\n",
    "                     keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "                     keras.layers.Dropout(0.25),\n",
    "                         \n",
    "                     keras.layers.Flatten(),                     \n",
    "                     keras.layers.Dense(256, activation='relu'), # 512\n",
    "                     keras.layers.Dropout(0.5),\n",
    "                     keras.layers.Dense(num_classes, activation='softmax')    \n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_acc',\n",
    "                                              patience=10, \n",
    "                                              restore_best_weights=True)\n",
    "\n",
    "history = model.fit_generator(train_generator,\n",
    "                              steps_per_epoch= train_num // batch_size,\n",
    "                              epochs=200,\n",
    "                              validation_data=validation_generator,\n",
    "                              validation_steps= validation_num // batch_size,\n",
    "                              callbacks=[early_stopping])#0.8232 --> 0.8625"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6.723012447357178, 0.5718727707862854]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate_generator(test_generator, test_generator.samples) # [8.29, 0.5693] --> [6.72, 0.5719]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transfert Learning VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "35/35 [==============================] - 3027s 86s/step - loss: 1.4699 - acc: 0.3336 - val_loss: 1.2734 - val_acc: 0.3906\n",
      "Epoch 2/20\n",
      "35/35 [==============================] - 3811s 109s/step - loss: 1.0894 - acc: 0.4957 - val_loss: 1.1094 - val_acc: 0.4322\n",
      "Epoch 3/20\n",
      "35/35 [==============================] - 3966s 113s/step - loss: 0.9069 - acc: 0.6117 - val_loss: 0.9317 - val_acc: 0.5324\n",
      "Epoch 4/20\n",
      "35/35 [==============================] - 3346s 96s/step - loss: 0.7819 - acc: 0.6785 - val_loss: 0.8439 - val_acc: 0.6169\n",
      "Epoch 5/20\n",
      "35/35 [==============================] - 1487s 42s/step - loss: 0.7166 - acc: 0.7170 - val_loss: 0.9929 - val_acc: 0.6365\n",
      "Epoch 6/20\n",
      "35/35 [==============================] - 1626s 46s/step - loss: 0.5780 - acc: 0.7801 - val_loss: 0.6093 - val_acc: 0.7367\n",
      "Epoch 7/20\n",
      "35/35 [==============================] - 1533s 44s/step - loss: 0.5200 - acc: 0.8052 - val_loss: 0.7611 - val_acc: 0.7171\n",
      "Epoch 8/20\n",
      "35/35 [==============================] - 1417s 40s/step - loss: 0.5627 - acc: 0.7927 - val_loss: 0.6445 - val_acc: 0.6974\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 9/20\n",
      "35/35 [==============================] - 1410s 40s/step - loss: 0.4768 - acc: 0.8312 - val_loss: 0.7518 - val_acc: 0.7466\n",
      "Epoch 10/20\n",
      "35/35 [==============================] - 1385s 40s/step - loss: 0.4395 - acc: 0.8335 - val_loss: 0.7006 - val_acc: 0.7461\n",
      "Epoch 11/20\n",
      "35/35 [==============================] - 1620s 46s/step - loss: 0.4042 - acc: 0.8607 - val_loss: 0.6312 - val_acc: 0.7701\n",
      "Epoch 12/20\n",
      "35/35 [==============================] - 2059s 59s/step - loss: 0.4046 - acc: 0.8558 - val_loss: 0.5175 - val_acc: 0.7446\n",
      "Epoch 13/20\n",
      "35/35 [==============================] - 1521s 43s/step - loss: 0.3827 - acc: 0.8657 - val_loss: 0.6349 - val_acc: 0.7662\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 14/20\n",
      "35/35 [==============================] - 2219s 63s/step - loss: 0.3814 - acc: 0.8652 - val_loss: 0.7058 - val_acc: 0.7348\n",
      "Epoch 15/20\n",
      "35/35 [==============================] - 1323s 38s/step - loss: 0.3832 - acc: 0.8661 - val_loss: 0.8087 - val_acc: 0.7780\n",
      "Epoch 16/20\n",
      "35/35 [==============================] - 1309s 37s/step - loss: 0.3978 - acc: 0.8567 - val_loss: 0.5249 - val_acc: 0.7741\n",
      "Epoch 17/20\n",
      "35/35 [==============================] - 1371s 39s/step - loss: 0.3469 - acc: 0.8679 - val_loss: 0.5880 - val_acc: 0.7564\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 18/20\n",
      "35/35 [==============================] - 1346s 38s/step - loss: 0.4083 - acc: 0.8580 - val_loss: 0.4678 - val_acc: 0.7603\n",
      "Epoch 19/20\n",
      "35/35 [==============================] - 1316s 38s/step - loss: 0.3994 - acc: 0.8504 - val_loss: 0.7505 - val_acc: 0.7461\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 1e-06.\n"
     ]
    }
   ],
   "source": [
    "# Lien Kaggle : https://www.kaggle.com/madz2000/flowers-classification-using-vgg19-87-accuracy\n",
    "\n",
    "pre_trained_model = keras.applications.VGG19(input_shape=(224,224,3),\n",
    "                                             include_top=False,\n",
    "                                             weights=\"imagenet\")\n",
    "\n",
    "#pre_trained_model.trainable = False\n",
    "\n",
    "for layer in pre_trained_model.layers[:19]: #There are 19 layers in VGG19 model. So I freezed the weights of the first 18 layers except for the last layer so that they don't get updated during backpropagation.\n",
    "    layer.trainable = False\n",
    "\n",
    "model = keras.models.Sequential([pre_trained_model,\n",
    "                                 keras.layers.MaxPool2D((2,2) , strides = 2),\n",
    "                                 keras.layers.Flatten(),\n",
    "                                 keras.layers.Dense(num_classes , activation='softmax')])\n",
    "\n",
    "model.compile(optimizer = \"adam\" , loss = 'categorical_crossentropy', metrics = ['acc'])\n",
    "\n",
    "learning_rate_reduction = keras.callbacks.ReduceLROnPlateau(monitor='val_acc', patience = 2, verbose=1, factor=0.1, min_lr=0.000001)\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_acc',\n",
    "                                              patience=4, \n",
    "                                              restore_best_weights=True)\n",
    "\n",
    "history = model.fit_generator(train_generator,\n",
    "                              steps_per_epoch= train_num // batch_size,\n",
    "                              epochs=20,\n",
    "                              validation_data=validation_generator,\n",
    "                              validation_steps= validation_num // batch_size,\n",
    "                              callbacks=[learning_rate_reduction,early_stopping])#0.8232 --> 0.8625 --> 0.6483 --> 0.8114"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.9205785989761353, 0.6482966542243958]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate_generator(test_generator, test_generator.samples) # [1.6427531242370605, 0.6788932681083679]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
